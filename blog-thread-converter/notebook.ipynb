{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Content Planning and Publishing Crew -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- This notebook demonstrates how to create an AI crew for planning and publishing content using CrewAI Flows.\n",
    "The crew will take a link to blog post, download content as markdown using firecrawl, analyze it and generate a twitter thread and schedule it on Typefully. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Initialization and Setup\n",
    "Initial imports for the CrewAI Flow and Crew and setting up the environment -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import getpass\n",
    "import os\n",
    "import datetime\n",
    "import uuid\n",
    "import yaml\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pydantic\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "# Firecrawl SDK\n",
    "from firecrawl import FirecrawlApp\n",
    "\n",
    "# Typefully scheduler\n",
    "import scheduler\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow import Flow, listen, start, router, or_\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Setup LLM\n",
    "\n",
    "Make sure you have ollama installed and running on your machine -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, the llm is set to openai\n",
    "#  llm = LLM(\n",
    "#     model=\"ollama/llama3.2\",\n",
    "#     base_url=\"http://localhost:11434\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Blog Post URL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_post_url =\"https://www.firecrawl.dev/blog/ai-powered-web-scraping-solutions-2025\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Plan for our Flow\n",
    "\n",
    "1. Scrape the blog post\n",
    "2. Decode where to post using a router\n",
    "3. Kickoff the right **[Crew of Agents]** to prepare a draft ready to publish\n",
    "4. Publish it using typefully -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Twitter Thread Planning Crew\n",
    "\n",
    "This structure will be used to capture the output of the planning crew which will be used to create the twitter thread and schedule it on Typefully. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet(BaseModel):\n",
    "    \"\"\"Represents an individual tweet in a thread\"\"\"\n",
    "    content: str\n",
    "    is_hook: bool = False  # Identifies if this is the opening/hook tweet\n",
    "    media_urls: Optional[list[str]] = []  # Optional media attachments (images, code snippets)\n",
    "\n",
    "class Thread(BaseModel):\n",
    "    \"\"\"Represents a Twitter thread\"\"\"\n",
    "    topic: str  # Main topic/subject of the thread\n",
    "    tweets: list[Tweet]  # List of tweets in the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"schema\" in \"DatabricksQueryToolSchema\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/planner_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/planner_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_analyzer = Agent(config=agents_config['draft_analyzer'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "])\n",
    "twitter_thread_planner = Agent(config=agents_config['twitter_thread_planner'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "])\n",
    "\n",
    "analyze_draft = Task(\n",
    "  config=tasks_config['analyze_draft'],\n",
    "  agent=draft_analyzer\n",
    ")\n",
    "create_twitter_thread_plan = Task(\n",
    "  config=tasks_config['create_twitter_thread_plan'],\n",
    "  agent=twitter_thread_planner,\n",
    "  output_pydantic=Thread\n",
    ")\n",
    "\n",
    "planning_crew = Crew(\n",
    "    agents=[draft_analyzer, twitter_thread_planner],\n",
    "    tasks=[analyze_draft, create_twitter_thread_plan],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # LinkedIn Post Planning Crew -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Create Content Planning Flow\n",
    "\n",
    "A Flow to create the content planning for twitter and linkedin using separate crews for twitter and linkedin -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, start, router, or_\n",
    "import re\n",
    "class ContentPlanningState(BaseModel):\n",
    "  \"\"\"\n",
    "  State for the content planning flow\n",
    "  \"\"\"\n",
    "  blog_post_url: str = blog_post_url\n",
    "  draft_path: Path = \"workdir/\"\n",
    "  post_type: str = \"twitter\"\n",
    "  path_to_example_threads: str = \"workdir/example_thread.txt\"\n",
    "\n",
    "\n",
    "\n",
    "class CreateContentPlanningFlow(Flow[ContentPlanningState]):\n",
    "  # Scrape the blog post  \n",
    "  # No need for AI Agents on this step, so we just use regular Python code\n",
    "  @start()\n",
    "  def scrape_blog_post(self):\n",
    "    print(f\"# fetching draft from: {self.state.blog_post_url}\")\n",
    "    app = FirecrawlApp(api_key=os.getenv(\"FIRECRAWL_API_KEY\"))\n",
    "    scrape_result = app.scrape_url(self.state.blog_post_url, formats=['markdown'])\n",
    "    markdown = scrape_result['markdown'] if isinstance(scrape_result, dict) else scrape_result.markdown\n",
    "    os.makedirs('workdir', exist_ok=True)  # <-- Add this line\n",
    "    self.state.draft_path = f'workdir/myblog.md'\n",
    "    with open(self.state.draft_path, 'w') as f:\n",
    "        f.write(markdown)\n",
    "\n",
    "\n",
    "  @listen(scrape_blog_post)\n",
    "  def twitter_draft(self):\n",
    "    print(f\"# Planning content for: {self.state.draft_path}\")\n",
    "    result = planning_crew.kickoff(inputs={'draft_path': self.state.draft_path,\n",
    "                                           'path_to_example_threads': self.state.path_to_example_threads})\n",
    "    print(f\"# Planned content for {self.state.draft_path}:\")\n",
    "    for tweet in result.pydantic.tweets:\n",
    "        print(f\"    - {tweet.content}\")\n",
    "    return result\n",
    "  \n",
    "  @listen(twitter_draft)\n",
    "  def publish(self, plan):\n",
    "    print(f\"# Publishing thread for: {self.state.draft_path}\")\n",
    "    ## Schedule for 1 hour from now    \n",
    "    response = scheduler.schedule(\n",
    "        thread_model=plan,\n",
    "        post_type=self.state.post_type\n",
    "    )\n",
    "    print(f\"# Thread created for: {self.state.draft_path}\")\n",
    "    print(f\"Here's the link to the created draft: {response['share_url']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Implementing helper methods to plot and execute the flow in a Jupyter notebook -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────── Flow Execution ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Starting Flow Execution</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────\u001b[0m\u001b[34m Flow Execution \u001b[0m\u001b[34m────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34mStarting Flow Execution\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "└── <span style=\"color: #808000; text-decoration-color: #808000\">🧠 Starting Flow...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "└── \u001b[33m🧠 Starting Flow...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m Flow started with ID: 8112d170-8f67-4814-b088-acdcfd111147\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #808000; text-decoration-color: #808000\">🧠 Starting Flow...</span>\n",
       "└── <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">🔄 Running: scrape_blog_post</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[33m🧠 Starting Flow...\u001b[0m\n",
       "└── \u001b[1;33m🔄 Running:\u001b[0m\u001b[1;33m scrape_blog_post\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# fetching draft from: https://www.firecrawl.dev/blog/ai-powered-web-scraping-solutions-2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "└── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "└── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "└── <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">🔄 Running: twitter_draft</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n",
       "└── \u001b[1;33m🔄 Running:\u001b[0m\u001b[1;33m twitter_draft\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Planning content for: workdir/myblog.md\n",
      "# Planned content for workdir/myblog.md:\n",
      "    - Top 7 AI-Powered Web Scraping Solutions in 2025\n",
      "    - What is AI-Powered Web Scraping? 🤖\n",
      "\n",
      "It's a game-changer! Users can now communicate data needs in plain language, allowing complex web structures to be navigated easily. A huge leap from traditional methods! #WebScraping #AI\n",
      "    - Leading AI Web Scraping Solutions 🌟\n",
      "\n",
      "Discover tools that handle JavaScript, manage proxies automatically, and process natural language seamlessly—making data extraction accessible to everyone! #TechInnovation\n",
      "    - Why Firecrawl is the Best Choice 🔥\n",
      "\n",
      "Advanced features like real-time adaptation, anti-bot countermeasures, and a developer-friendly API set it apart in the world of AI scraping! #DataExtraction\n",
      "    - Other Notable AI Scraping Tools 🚀\n",
      "\n",
      "Explore ScrapingBee, Import.io, Browse.AI & others. Get the features you need, whether you're an indie dev or part of a large enterprise! #WebScrapingTools\n",
      "    - Key Takeaway for Developers 🧑‍💻:\n",
      "\n",
      "AI scraping tools empower devs to extract data easily without deep knowledge of web technologies—leaving more time for innovation! #Programming\n",
      "    - Real-World Applications 🌍:\n",
      "\n",
      "From market research to competitive analysis, AI web scraping transforms how businesses gather data, creating opportunities across industries!\n",
      "\n",
      "#BusinessIntelligence\n",
      "    - Final Thoughts 💭:\n",
      "\n",
      "As AI evolves, so will web scraping capabilities. Embrace these tools to stay ahead! What’s your go-to scraping tool? Let me know! 👇\n",
      "\n",
      "#AI #WebScraping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "└── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: twitter_draft</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n",
       "└── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m twitter_draft\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: twitter_draft</span>\n",
       "└── <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">🔄 Running: publish</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m twitter_draft\u001b[0m\n",
       "└── \u001b[1;33m🔄 Running:\u001b[0m\u001b[1;33m publish\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Publishing thread for: workdir/myblog.md\n",
      "######## Thread JSON:  {'topic': 'Top 7 AI-Powered Web Scraping Solutions in 2025', 'tweets': [{'content': 'Top 7 AI-Powered Web Scraping Solutions in 2025', 'is_hook': True, 'media_urls': []}, {'content': \"What is AI-Powered Web Scraping? 🤖\\n\\nIt's a game-changer! Users can now communicate data needs in plain language, allowing complex web structures to be navigated easily. A huge leap from traditional methods! #WebScraping #AI\", 'is_hook': False, 'media_urls': ['https://www.firecrawl.dev/images/blog/ai-scraping-tools/ai-scraping-tools.jpg']}, {'content': 'Leading AI Web Scraping Solutions 🌟\\n\\nDiscover tools that handle JavaScript, manage proxies automatically, and process natural language seamlessly—making data extraction accessible to everyone! #TechInnovation', 'is_hook': False, 'media_urls': ['https://www.firecrawl.dev/images/blog/ai-scraping-tools/firecrawl.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/extract.chat.png']}, {'content': 'Why Firecrawl is the Best Choice 🔥\\n\\nAdvanced features like real-time adaptation, anti-bot countermeasures, and a developer-friendly API set it apart in the world of AI scraping! #DataExtraction', 'is_hook': False, 'media_urls': ['https://www.firecrawl.dev/images/blog/ai-scraping-tools/firecrawl.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/extract.chat.png']}, {'content': \"Other Notable AI Scraping Tools 🚀\\n\\nExplore ScrapingBee, Import.io, Browse.AI & others. Get the features you need, whether you're an indie dev or part of a large enterprise! #WebScrapingTools\", 'is_hook': False, 'media_urls': ['https://www.firecrawl.dev/images/blog/ai-scraping-tools/scraping-bee.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/import.io.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/browse.ai.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/kadoa.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/diffbot.png', 'https://www.firecrawl.dev/images/blog/ai-scraping-tools/octoparse.png']}, {'content': 'Key Takeaway for Developers 🧑\\u200d💻:\\n\\nAI scraping tools empower devs to extract data easily without deep knowledge of web technologies—leaving more time for innovation! #Programming', 'is_hook': False, 'media_urls': []}, {'content': 'Real-World Applications 🌍:\\n\\nFrom market research to competitive analysis, AI web scraping transforms how businesses gather data, creating opportunities across industries!\\n\\n#BusinessIntelligence', 'is_hook': False, 'media_urls': []}, {'content': 'Final Thoughts 💭:\\n\\nAs AI evolves, so will web scraping capabilities. Embrace these tools to stay ahead! What’s your go-to scraping tool? Let me know! 👇\\n\\n#AI #WebScraping', 'is_hook': False, 'media_urls': []}]}\n",
      "Thread created successfully!\n",
      "# Thread created for: workdir/myblog.md\n",
      "Here's the link to the created draft: https://typefully.com/t/AonkFQq\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">🌊 Flow: </span><span style=\"color: #000080; text-decoration-color: #000080\">CreateContentPlanningFlow</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    ID: </span><span style=\"color: #000080; text-decoration-color: #000080\">8112d170-8f67-4814-b088-acdcfd111147</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: twitter_draft</span>\n",
       "└── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: publish</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m🌊 Flow: \u001b[0m\u001b[34mCreateContentPlanningFlow\u001b[0m\n",
       "\u001b[37m    ID: \u001b[0m\u001b[34m8112d170-8f67-4814-b088-acdcfd111147\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m twitter_draft\u001b[0m\n",
       "└── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m publish\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Flow Finished: </span><span style=\"color: #008000; text-decoration-color: #008000\">CreateContentPlanningFlow</span>\n",
       "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Flow Method Step</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: scrape_blog_post</span>\n",
       "├── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: twitter_draft</span>\n",
       "└── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Completed: publish</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ Flow Finished: \u001b[0m\u001b[32mCreateContentPlanningFlow\u001b[0m\n",
       "├── \u001b[37mFlow Method Step\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m scrape_blog_post\u001b[0m\n",
       "├── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m twitter_draft\u001b[0m\n",
       "└── \u001b[1;32m✅ Completed:\u001b[0m\u001b[1;32m publish\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow = CreateContentPlanningFlow()\n",
    "flow.kickoff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
